{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 7460,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013404825737265416,
      "grad_norm": 0.9371768832206726,
      "learning_rate": 0.0009865951742627345,
      "loss": 0.6431,
      "step": 100
    },
    {
      "epoch": 0.02680965147453083,
      "grad_norm": 3.3748440742492676,
      "learning_rate": 0.0009731903485254692,
      "loss": 0.3471,
      "step": 200
    },
    {
      "epoch": 0.040214477211796246,
      "grad_norm": 1.5545932054519653,
      "learning_rate": 0.0009597855227882038,
      "loss": 0.3666,
      "step": 300
    },
    {
      "epoch": 0.05361930294906166,
      "grad_norm": 2.3838040828704834,
      "learning_rate": 0.0009463806970509384,
      "loss": 0.3065,
      "step": 400
    },
    {
      "epoch": 0.06702412868632708,
      "grad_norm": 2.1048314571380615,
      "learning_rate": 0.0009329758713136729,
      "loss": 0.3073,
      "step": 500
    },
    {
      "epoch": 0.08042895442359249,
      "grad_norm": 0.9442209005355835,
      "learning_rate": 0.0009195710455764074,
      "loss": 0.2941,
      "step": 600
    },
    {
      "epoch": 0.0938337801608579,
      "grad_norm": 1.0935646295547485,
      "learning_rate": 0.0009061662198391421,
      "loss": 0.2903,
      "step": 700
    },
    {
      "epoch": 0.10723860589812333,
      "grad_norm": 2.2654151916503906,
      "learning_rate": 0.0008927613941018767,
      "loss": 0.3094,
      "step": 800
    },
    {
      "epoch": 0.12064343163538874,
      "grad_norm": 3.9198176860809326,
      "learning_rate": 0.0008793565683646113,
      "loss": 0.2762,
      "step": 900
    },
    {
      "epoch": 0.13404825737265416,
      "grad_norm": 1.554687738418579,
      "learning_rate": 0.0008659517426273459,
      "loss": 0.2843,
      "step": 1000
    },
    {
      "epoch": 0.14745308310991956,
      "grad_norm": 2.0323853492736816,
      "learning_rate": 0.0008525469168900805,
      "loss": 0.2745,
      "step": 1100
    },
    {
      "epoch": 0.16085790884718498,
      "grad_norm": 1.9274580478668213,
      "learning_rate": 0.0008391420911528151,
      "loss": 0.2919,
      "step": 1200
    },
    {
      "epoch": 0.1742627345844504,
      "grad_norm": 1.7596408128738403,
      "learning_rate": 0.0008257372654155496,
      "loss": 0.321,
      "step": 1300
    },
    {
      "epoch": 0.1876675603217158,
      "grad_norm": 1.4947774410247803,
      "learning_rate": 0.0008123324396782842,
      "loss": 0.2443,
      "step": 1400
    },
    {
      "epoch": 0.20107238605898123,
      "grad_norm": 4.142843723297119,
      "learning_rate": 0.0007989276139410187,
      "loss": 0.2723,
      "step": 1500
    },
    {
      "epoch": 0.21447721179624665,
      "grad_norm": 0.26338332891464233,
      "learning_rate": 0.0007855227882037533,
      "loss": 0.2917,
      "step": 1600
    },
    {
      "epoch": 0.22788203753351208,
      "grad_norm": 0.921812891960144,
      "learning_rate": 0.0007721179624664879,
      "loss": 0.2397,
      "step": 1700
    },
    {
      "epoch": 0.24128686327077747,
      "grad_norm": 3.5690720081329346,
      "learning_rate": 0.0007587131367292225,
      "loss": 0.2681,
      "step": 1800
    },
    {
      "epoch": 0.2546916890080429,
      "grad_norm": 1.9240695238113403,
      "learning_rate": 0.0007453083109919572,
      "loss": 0.2716,
      "step": 1900
    },
    {
      "epoch": 0.2680965147453083,
      "grad_norm": 0.22423110902309418,
      "learning_rate": 0.0007319034852546918,
      "loss": 0.2816,
      "step": 2000
    },
    {
      "epoch": 0.28150134048257375,
      "grad_norm": 0.5700041055679321,
      "learning_rate": 0.0007184986595174263,
      "loss": 0.2504,
      "step": 2100
    },
    {
      "epoch": 0.2949061662198391,
      "grad_norm": 1.8328019380569458,
      "learning_rate": 0.0007050938337801609,
      "loss": 0.249,
      "step": 2200
    },
    {
      "epoch": 0.30831099195710454,
      "grad_norm": 2.9990627765655518,
      "learning_rate": 0.0006916890080428954,
      "loss": 0.2276,
      "step": 2300
    },
    {
      "epoch": 0.32171581769436997,
      "grad_norm": 1.0322630405426025,
      "learning_rate": 0.00067828418230563,
      "loss": 0.2603,
      "step": 2400
    },
    {
      "epoch": 0.3351206434316354,
      "grad_norm": 2.0965845584869385,
      "learning_rate": 0.0006648793565683646,
      "loss": 0.2404,
      "step": 2500
    },
    {
      "epoch": 0.3485254691689008,
      "grad_norm": 3.229182481765747,
      "learning_rate": 0.0006514745308310992,
      "loss": 0.2419,
      "step": 2600
    },
    {
      "epoch": 0.36193029490616624,
      "grad_norm": 3.7733023166656494,
      "learning_rate": 0.0006380697050938338,
      "loss": 0.2379,
      "step": 2700
    },
    {
      "epoch": 0.3753351206434316,
      "grad_norm": 0.6866495013237,
      "learning_rate": 0.0006246648793565684,
      "loss": 0.2408,
      "step": 2800
    },
    {
      "epoch": 0.38873994638069703,
      "grad_norm": 1.8629108667373657,
      "learning_rate": 0.0006112600536193029,
      "loss": 0.2518,
      "step": 2900
    },
    {
      "epoch": 0.40214477211796246,
      "grad_norm": 1.1616536378860474,
      "learning_rate": 0.0005978552278820375,
      "loss": 0.2244,
      "step": 3000
    },
    {
      "epoch": 0.4155495978552279,
      "grad_norm": 1.7771563529968262,
      "learning_rate": 0.000584450402144772,
      "loss": 0.2634,
      "step": 3100
    },
    {
      "epoch": 0.4289544235924933,
      "grad_norm": 1.8796429634094238,
      "learning_rate": 0.0005710455764075067,
      "loss": 0.2265,
      "step": 3200
    },
    {
      "epoch": 0.44235924932975873,
      "grad_norm": 0.6979507207870483,
      "learning_rate": 0.0005576407506702413,
      "loss": 0.2214,
      "step": 3300
    },
    {
      "epoch": 0.45576407506702415,
      "grad_norm": 0.38930749893188477,
      "learning_rate": 0.0005442359249329759,
      "loss": 0.2064,
      "step": 3400
    },
    {
      "epoch": 0.4691689008042895,
      "grad_norm": 0.9605860114097595,
      "learning_rate": 0.0005308310991957105,
      "loss": 0.2281,
      "step": 3500
    },
    {
      "epoch": 0.48257372654155495,
      "grad_norm": 3.158761739730835,
      "learning_rate": 0.0005174262734584451,
      "loss": 0.2369,
      "step": 3600
    },
    {
      "epoch": 0.4959785522788204,
      "grad_norm": 3.742438316345215,
      "learning_rate": 0.0005040214477211797,
      "loss": 0.2088,
      "step": 3700
    },
    {
      "epoch": 0.5093833780160858,
      "grad_norm": 1.531407117843628,
      "learning_rate": 0.0004906166219839142,
      "loss": 0.2034,
      "step": 3800
    },
    {
      "epoch": 0.5227882037533512,
      "grad_norm": 1.0006349086761475,
      "learning_rate": 0.0004772117962466488,
      "loss": 0.2332,
      "step": 3900
    },
    {
      "epoch": 0.5361930294906166,
      "grad_norm": 1.4236769676208496,
      "learning_rate": 0.00046380697050938335,
      "loss": 0.241,
      "step": 4000
    },
    {
      "epoch": 0.5495978552278821,
      "grad_norm": 0.4687250256538391,
      "learning_rate": 0.000450402144772118,
      "loss": 0.212,
      "step": 4100
    },
    {
      "epoch": 0.5630026809651475,
      "grad_norm": 2.0094141960144043,
      "learning_rate": 0.0004369973190348526,
      "loss": 0.2347,
      "step": 4200
    },
    {
      "epoch": 0.5764075067024129,
      "grad_norm": 2.402650833129883,
      "learning_rate": 0.00042359249329758717,
      "loss": 0.2158,
      "step": 4300
    },
    {
      "epoch": 0.5898123324396782,
      "grad_norm": 4.280385494232178,
      "learning_rate": 0.0004101876675603217,
      "loss": 0.2275,
      "step": 4400
    },
    {
      "epoch": 0.6032171581769437,
      "grad_norm": 1.1473586559295654,
      "learning_rate": 0.0003967828418230563,
      "loss": 0.2085,
      "step": 4500
    },
    {
      "epoch": 0.6166219839142091,
      "grad_norm": 2.0864880084991455,
      "learning_rate": 0.0003833780160857909,
      "loss": 0.234,
      "step": 4600
    },
    {
      "epoch": 0.6300268096514745,
      "grad_norm": 2.9303793907165527,
      "learning_rate": 0.0003699731903485255,
      "loss": 0.2094,
      "step": 4700
    },
    {
      "epoch": 0.6434316353887399,
      "grad_norm": 1.7826191186904907,
      "learning_rate": 0.00035656836461126005,
      "loss": 0.2454,
      "step": 4800
    },
    {
      "epoch": 0.6568364611260054,
      "grad_norm": 3.1986167430877686,
      "learning_rate": 0.00034316353887399464,
      "loss": 0.2415,
      "step": 4900
    },
    {
      "epoch": 0.6702412868632708,
      "grad_norm": 3.189154624938965,
      "learning_rate": 0.00032975871313672923,
      "loss": 0.2125,
      "step": 5000
    },
    {
      "epoch": 0.6836461126005362,
      "grad_norm": 19.10985565185547,
      "learning_rate": 0.0003163538873994638,
      "loss": 0.2283,
      "step": 5100
    },
    {
      "epoch": 0.6970509383378016,
      "grad_norm": 1.5353126525878906,
      "learning_rate": 0.00030294906166219835,
      "loss": 0.2125,
      "step": 5200
    },
    {
      "epoch": 0.710455764075067,
      "grad_norm": 1.9760171175003052,
      "learning_rate": 0.000289544235924933,
      "loss": 0.1624,
      "step": 5300
    },
    {
      "epoch": 0.7238605898123325,
      "grad_norm": 0.8415951132774353,
      "learning_rate": 0.0002761394101876676,
      "loss": 0.183,
      "step": 5400
    },
    {
      "epoch": 0.7372654155495979,
      "grad_norm": 1.5080480575561523,
      "learning_rate": 0.0002627345844504022,
      "loss": 0.2076,
      "step": 5500
    },
    {
      "epoch": 0.7506702412868632,
      "grad_norm": 0.9701162576675415,
      "learning_rate": 0.0002493297587131367,
      "loss": 0.216,
      "step": 5600
    },
    {
      "epoch": 0.7640750670241286,
      "grad_norm": 0.7772080898284912,
      "learning_rate": 0.0002359249329758713,
      "loss": 0.2165,
      "step": 5700
    },
    {
      "epoch": 0.7774798927613941,
      "grad_norm": 1.6370078325271606,
      "learning_rate": 0.0002225201072386059,
      "loss": 0.2152,
      "step": 5800
    },
    {
      "epoch": 0.7908847184986595,
      "grad_norm": 2.2852425575256348,
      "learning_rate": 0.0002091152815013405,
      "loss": 0.2255,
      "step": 5900
    },
    {
      "epoch": 0.8042895442359249,
      "grad_norm": 0.6477126479148865,
      "learning_rate": 0.00019571045576407506,
      "loss": 0.2066,
      "step": 6000
    },
    {
      "epoch": 0.8176943699731903,
      "grad_norm": 0.8896453380584717,
      "learning_rate": 0.00018230563002680968,
      "loss": 0.1773,
      "step": 6100
    },
    {
      "epoch": 0.8310991957104558,
      "grad_norm": 0.10707210749387741,
      "learning_rate": 0.00016890080428954424,
      "loss": 0.2185,
      "step": 6200
    },
    {
      "epoch": 0.8445040214477212,
      "grad_norm": 1.8271739482879639,
      "learning_rate": 0.00015549597855227883,
      "loss": 0.215,
      "step": 6300
    },
    {
      "epoch": 0.8579088471849866,
      "grad_norm": 0.6540551781654358,
      "learning_rate": 0.00014209115281501342,
      "loss": 0.2117,
      "step": 6400
    },
    {
      "epoch": 0.871313672922252,
      "grad_norm": 1.755246639251709,
      "learning_rate": 0.000128686327077748,
      "loss": 0.2013,
      "step": 6500
    },
    {
      "epoch": 0.8847184986595175,
      "grad_norm": 1.1833430528640747,
      "learning_rate": 0.00011528150134048257,
      "loss": 0.211,
      "step": 6600
    },
    {
      "epoch": 0.8981233243967829,
      "grad_norm": 3.5887503623962402,
      "learning_rate": 0.00010187667560321715,
      "loss": 0.2031,
      "step": 6700
    },
    {
      "epoch": 0.9115281501340483,
      "grad_norm": 1.9322704076766968,
      "learning_rate": 8.847184986595174e-05,
      "loss": 0.2082,
      "step": 6800
    },
    {
      "epoch": 0.9249329758713136,
      "grad_norm": 0.977975606918335,
      "learning_rate": 7.506702412868632e-05,
      "loss": 0.1839,
      "step": 6900
    },
    {
      "epoch": 0.938337801608579,
      "grad_norm": 0.577572762966156,
      "learning_rate": 6.16621983914209e-05,
      "loss": 0.2193,
      "step": 7000
    },
    {
      "epoch": 0.9517426273458445,
      "grad_norm": 1.7379941940307617,
      "learning_rate": 4.8257372654155495e-05,
      "loss": 0.1901,
      "step": 7100
    },
    {
      "epoch": 0.9651474530831099,
      "grad_norm": 0.48948734998703003,
      "learning_rate": 3.485254691689008e-05,
      "loss": 0.2088,
      "step": 7200
    },
    {
      "epoch": 0.9785522788203753,
      "grad_norm": 2.9719855785369873,
      "learning_rate": 2.1447721179624665e-05,
      "loss": 0.1925,
      "step": 7300
    },
    {
      "epoch": 0.9919571045576407,
      "grad_norm": 1.7933990955352783,
      "learning_rate": 8.04289544235925e-06,
      "loss": 0.2232,
      "step": 7400
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9328125,
      "eval_loss": 0.20605511963367462,
      "eval_runtime": 2.6328,
      "eval_samples_per_second": 243.083,
      "eval_steps_per_second": 3.798,
      "step": 7460
    }
  ],
  "logging_steps": 100,
  "max_steps": 7460,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0332814450087424e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
